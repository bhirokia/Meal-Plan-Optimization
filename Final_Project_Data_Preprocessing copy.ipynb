{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxZMRh-h8JJ6"
      },
      "source": [
        "# Final Project Data Preprocessing\n",
        "This notebook will go over all preprocessing necessary for our optimization model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VtYfejb76gV"
      },
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x4S5sbGF7FOu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchsummary import summary\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from tqdm import tqdm, trange\n",
        "import seaborn as sns\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4vvrgKZ8Wa0"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "PQIAnSJtXh97",
        "outputId": "81aae9c7-ad83-428e-882b-f8a1a5adaae1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   RecipeId                               Name  AuthorId      AuthorName  \\\n",
            "0        38  Low-Fat Berry Blue Frozen Dessert      1533          Dancer   \n",
            "1        39                            Biryani      1567        elly9812   \n",
            "2        40                      Best Lemonade      1566  Stephen Little   \n",
            "3        41     Carina's Tofu-Vegetable Kebabs      1586         Cyclopz   \n",
            "4        42                       Cabbage Soup      1538       Duckie067   \n",
            "\n",
            "  CookTime PrepTime TotalTime         DatePublished  \\\n",
            "0    PT24H    PT45M  PT24H45M  1999-08-09T21:46:00Z   \n",
            "1    PT25M     PT4H   PT4H25M  1999-08-29T13:12:00Z   \n",
            "2     PT5M    PT30M     PT35M  1999-09-05T19:52:00Z   \n",
            "3    PT20M    PT24H  PT24H20M  1999-09-03T14:54:00Z   \n",
            "4    PT30M    PT20M     PT50M  1999-09-19T06:19:00Z   \n",
            "\n",
            "                                         Description  \\\n",
            "0  Make and share this Low-Fat Berry Blue Frozen ...   \n",
            "1  Make and share this Biryani recipe from Food.com.   \n",
            "2  This is from one of my  first Good House Keepi...   \n",
            "3  This dish is best prepared a day in advance to...   \n",
            "4  Make and share this Cabbage Soup recipe from F...   \n",
            "\n",
            "                                              Images  ... SaturatedFatContent  \\\n",
            "0  c(\"https://img.sndimg.com/food/image/upload/w_...  ...                 1.3   \n",
            "1  c(\"https://img.sndimg.com/food/image/upload/w_...  ...                16.6   \n",
            "2  c(\"https://img.sndimg.com/food/image/upload/w_...  ...                 0.0   \n",
            "3  c(\"https://img.sndimg.com/food/image/upload/w_...  ...                 3.8   \n",
            "4  \"https://img.sndimg.com/food/image/upload/w_55...  ...                 0.1   \n",
            "\n",
            "  CholesterolContent SodiumContent CarbohydrateContent  FiberContent  \\\n",
            "0                8.0          29.8                37.1           3.6   \n",
            "1              372.8         368.4                84.4           9.0   \n",
            "2                0.0           1.8                81.5           0.4   \n",
            "3                0.0        1558.6                64.2          17.3   \n",
            "4                0.0         959.3                25.1           4.8   \n",
            "\n",
            "   SugarContent  ProteinContent  RecipeServings  RecipeYield  \\\n",
            "0          30.2             3.2             4.0          NaN   \n",
            "1          20.4            63.4             6.0          NaN   \n",
            "2          77.2             0.3             4.0          NaN   \n",
            "3          32.1            29.3             2.0     4 kebabs   \n",
            "4          17.7             4.3             4.0          NaN   \n",
            "\n",
            "                                  RecipeInstructions  \n",
            "0  c(\"Toss 2 cups berries with sugar.\", \"Let stan...  \n",
            "1  c(\"Soak saffron in warm milk for 5 minutes and...  \n",
            "2  c(\"Into a 1 quart Jar with tight fitting lid, ...  \n",
            "3  c(\"Drain the tofu, carefully squeezing out exc...  \n",
            "4  c(\"Mix everything together and bring to a boil...  \n",
            "\n",
            "[5 rows x 28 columns]\n",
            "   ReviewId  RecipeId  AuthorId        AuthorName  Rating  \\\n",
            "0         2       992      2008         gayg msft       5   \n",
            "1         7      4384      1634     Bill Hilbrich       4   \n",
            "2         9      4523      2046  Gay Gilmore ckpt       2   \n",
            "3        13      7435      1773     Malarkey Test       5   \n",
            "4        14        44      2085        Tony Small       5   \n",
            "\n",
            "                                              Review         DateSubmitted  \\\n",
            "0       better than any you can get at a restaurant!  2000-01-25T21:44:00Z   \n",
            "1  I cut back on the mayo, and made up the differ...  2001-10-17T16:49:59Z   \n",
            "2  i think i did something wrong because i could ...  2000-02-25T09:00:00Z   \n",
            "3  easily the best i have ever had.  juicy flavor...  2000-03-13T21:15:00Z   \n",
            "4                                 An excellent dish.  2000-03-28T12:51:00Z   \n",
            "\n",
            "           DateModified  \n",
            "0  2000-01-25T21:44:00Z  \n",
            "1  2001-10-17T16:49:59Z  \n",
            "2  2000-02-25T09:00:00Z  \n",
            "3  2000-03-13T21:15:00Z  \n",
            "4  2000-03-28T12:51:00Z  \n",
            "recipes shape: (522517, 28)\n",
            "reviews shape: (1401982, 8)\n"
          ]
        }
      ],
      "source": [
        "# Define the local file path\n",
        "file_path_recipes = 'recipes.csv'\n",
        "file_path_reviews = 'reviews.csv'\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "recipes = pd.read_csv(file_path_recipes)\n",
        "reviews = pd.read_csv(file_path_reviews)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(recipes.head())\n",
        "print(reviews.head())\n",
        "\n",
        "print(\"recipes shape: \" + str(recipes.shape))\n",
        "print(\"reviews shape: \" + str(reviews.shape))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Observing Data\n",
        "Here, I analyzed the data to observe the shape and types of datapoints in the given data. This helps to better understand the data to see what pre-processing will be necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hL3j7OGh6pUT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    Make and share this Low-Fat Berry Blue Frozen ...\n",
            "1    Make and share this Biryani recipe from Food.com.\n",
            "2    This is from one of my  first Good House Keepi...\n",
            "3    This dish is best prepared a day in advance to...\n",
            "4    Make and share this Cabbage Soup recipe from F...\n",
            "Name: Description, dtype: object\n",
            "(522517,)\n",
            "Index(['RecipeId', 'Name', 'AuthorId', 'AuthorName', 'CookTime', 'PrepTime',\n",
            "       'TotalTime', 'DatePublished', 'Description', 'Images', 'RecipeCategory',\n",
            "       'Keywords', 'RecipeIngredientQuantities', 'RecipeIngredientParts',\n",
            "       'AggregatedRating', 'ReviewCount', 'Calories', 'FatContent',\n",
            "       'SaturatedFatContent', 'CholesterolContent', 'SodiumContent',\n",
            "       'CarbohydrateContent', 'FiberContent', 'SugarContent', 'ProteinContent',\n",
            "       'RecipeServings', 'RecipeYield', 'RecipeInstructions'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "descriptions = recipes['Description']\n",
        "print(descriptions.head())\n",
        "print(descriptions.shape)\n",
        "print(recipes.columns)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "MLC_blPA7LyF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(30552, 21)\n",
            "   RecipeId                       Name  AuthorId  \\\n",
            "0        88         Breakfast Burritos      1575   \n",
            "1       148                  Bugwiches      1579   \n",
            "2       170     Amish Six Layer Dinner      1534   \n",
            "3       314  Thai Citrus Chicken Salad    148316   \n",
            "4       557   Baked Breakfast Potatoes      1533   \n",
            "\n",
            "                                         Description RecipeCategory  \\\n",
            "0  Make and share this Breakfast Burritos recipe ...      Breakfast   \n",
            "1  A little bit of fun for the kids this summer. ...   Lunch/Snacks   \n",
            "2  Make and share this Amish Six Layer Dinner rec...      Vegetable   \n",
            "3  This is a healthy and delicious summer salad. ...        Chicken   \n",
            "4  Make and share this Baked Breakfast Potatoes r...      Breakfast   \n",
            "\n",
            "                                            Keywords  \\\n",
            "0                  c(\"Mexican\", \"< 60 Mins\", \"Easy\")   \n",
            "1  c(\"Tuna\", \"Very Low Carbs\", \"Low Protein\", \"Lo...   \n",
            "2  c(\"Meat\", \"Low Cholesterol\", \"Weeknight\", \"Ove...   \n",
            "3  c(\"Oranges\", \"Poultry\", \"Citrus\", \"Fruit\", \"Me...   \n",
            "4  c(\"Potato\", \"Vegetable\", \"Weeknight\", \"Oven\", ...   \n",
            "\n",
            "                          RecipeIngredientQuantities  \\\n",
            "0                             c(\"8\", \"1\", \"2\", \"10\")   \n",
            "1     c(\"1\", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA)   \n",
            "2  c(\"2\", \"2\", \"2\", \"1/2\", \"2\", \"1/4\", \"1\", \"2\", NA)   \n",
            "3  c(\"1\", \"1\", \"2\", \"1/4\", \"2\", \"1\", \"1\", \"2\", \"1...   \n",
            "4        c(\"1\", \"1/4\", \"1\", \"1\", \"4\", \"4\", \"2\", \"1\")   \n",
            "\n",
            "                               RecipeIngredientParts  AggregatedRating  \\\n",
            "0    c(\"eggs\", \"country sausage\", \"flour tortillas\")               3.5   \n",
            "1  c(\"carrot\", \"lettuce\", \"cucumber\", \"radish\", \"...               NaN   \n",
            "2  c(\"ground beef\", \"raw potatoes\", \"celery\", \"on...               4.0   \n",
            "3  c(\"garlic clove\", \"light soy sauce\", \"oranges\"...               5.0   \n",
            "4  c(\"black pepper\", \"nonfat sour cream\", \"sour c...               5.0   \n",
            "\n",
            "   ReviewCount  ...  FatContent  SaturatedFatContent  CholesterolContent  \\\n",
            "0          3.0  ...       112.2                 41.1               656.1   \n",
            "1          1.0  ...         2.0                  0.5                 0.3   \n",
            "2          8.0  ...        16.9                  6.5                74.8   \n",
            "3         15.0  ...         3.7                  1.0                73.1   \n",
            "4          2.0  ...         1.6                  1.0                 7.1   \n",
            "\n",
            "   SodiumContent  CarbohydrateContent  FiberContent  SugarContent  \\\n",
            "0         4146.0                150.2           8.8           9.3   \n",
            "1          145.9                 14.1           0.8           0.7   \n",
            "2         1453.8                 23.1           4.7           6.1   \n",
            "3          415.4                 40.9           8.6          26.9   \n",
            "4          136.2                 26.7           2.1           4.9   \n",
            "\n",
            "   ProteinContent  RecipeServings  RecipeYield  \n",
            "0            84.7             4.0          NaN  \n",
            "1             2.4             1.0          NaN  \n",
            "2            23.8             4.0          NaN  \n",
            "3            32.7             2.0          NaN  \n",
            "4             7.4            10.0          NaN  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "      labels\n",
            "0  breakfast\n",
            "1     dinner\n",
            "2     dinner\n",
            "3      lunch\n",
            "4  breakfast\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/562344202.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data.drop(columns=['AuthorName', 'CookTime', 'PrepTime', 'TotalTime','DatePublished','Images', 'RecipeInstructions'], inplace=True)\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "#Find all recipes with descriptions that include breakfast, lunch, or dinner\n",
        "rows = []\n",
        "labels = []\n",
        "key_words = [\"breakfast\", \"lunch\", \"dinner\"]\n",
        "\n",
        "for i in range(recipes.shape[0]):\n",
        "  description = recipes['Description'][i]\n",
        "  for j in range(len(key_words)):\n",
        "    if isinstance(description, str) and key_words[j] in description.lower():\n",
        "      rows.append(i)\n",
        "      labels.append(key_words[j])\n",
        "      break\n",
        "\n",
        "description_training_data = recipes.iloc[rows]\n",
        "\n",
        "description_training_data.drop(columns=['AuthorName', 'CookTime', 'PrepTime', 'TotalTime','DatePublished','Images', 'RecipeInstructions'], inplace=True)\n",
        "\n",
        "description_training_data.reset_index(inplace=True, drop=True)\n",
        "description_training_labels = pd.DataFrame(labels, columns=['labels'])\n",
        "\n",
        "print(description_training_data.shape)\n",
        "\n",
        "print(description_training_data.head())\n",
        "print(description_training_labels.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n",
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   RecipeId                       Name  AuthorId  \\\n",
            "0      88.0         Breakfast Burritos    1575.0   \n",
            "1     148.0                  Bugwiches    1579.0   \n",
            "2     170.0     Amish Six Layer Dinner    1534.0   \n",
            "3     314.0  Thai Citrus Chicken Salad  148316.0   \n",
            "4     557.0   Baked Breakfast Potatoes    1533.0   \n",
            "\n",
            "                                         Description RecipeCategory  \\\n",
            "0  Make and share this Breakfast Burritos recipe ...      Breakfast   \n",
            "1  A little bit of fun for the kids this summer. ...   Lunch/Snacks   \n",
            "2  Make and share this Amish Six Layer Dinner rec...      Vegetable   \n",
            "3  This is a healthy and delicious summer salad. ...        Chicken   \n",
            "4  Make and share this Baked Breakfast Potatoes r...      Breakfast   \n",
            "\n",
            "                                            Keywords  \\\n",
            "0                  c(\"Mexican\", \"< 60 Mins\", \"Easy\")   \n",
            "1  c(\"Tuna\", \"Very Low Carbs\", \"Low Protein\", \"Lo...   \n",
            "2  c(\"Meat\", \"Low Cholesterol\", \"Weeknight\", \"Ove...   \n",
            "3  c(\"Oranges\", \"Poultry\", \"Citrus\", \"Fruit\", \"Me...   \n",
            "4  c(\"Potato\", \"Vegetable\", \"Weeknight\", \"Oven\", ...   \n",
            "\n",
            "                          RecipeIngredientQuantities  \\\n",
            "0                             c(\"8\", \"1\", \"2\", \"10\")   \n",
            "1     c(\"1\", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA)   \n",
            "2  c(\"2\", \"2\", \"2\", \"1/2\", \"2\", \"1/4\", \"1\", \"2\", NA)   \n",
            "3  c(\"1\", \"1\", \"2\", \"1/4\", \"2\", \"1\", \"1\", \"2\", \"1...   \n",
            "4        c(\"1\", \"1/4\", \"1\", \"1\", \"4\", \"4\", \"2\", \"1\")   \n",
            "\n",
            "                               RecipeIngredientParts  AggregatedRating  \\\n",
            "0    c(\"eggs\", \"country sausage\", \"flour tortillas\")          3.500000   \n",
            "1  c(\"carrot\", \"lettuce\", \"cucumber\", \"radish\", \"...          4.646373   \n",
            "2  c(\"ground beef\", \"raw potatoes\", \"celery\", \"on...          4.000000   \n",
            "3  c(\"garlic clove\", \"light soy sauce\", \"oranges\"...          5.000000   \n",
            "4  c(\"black pepper\", \"nonfat sour cream\", \"sour c...          5.000000   \n",
            "\n",
            "   ReviewCount  ...  FatContent  SaturatedFatContent  CholesterolContent  \\\n",
            "0          3.0  ...       112.2                 41.1               656.1   \n",
            "1          1.0  ...         2.0                  0.5                 0.3   \n",
            "2          8.0  ...        16.9                  6.5                74.8   \n",
            "3         15.0  ...         3.7                  1.0                73.1   \n",
            "4          2.0  ...         1.6                  1.0                 7.1   \n",
            "\n",
            "   SodiumContent  CarbohydrateContent  FiberContent  SugarContent  \\\n",
            "0         4146.0                150.2           8.8           9.3   \n",
            "1          145.9                 14.1           0.8           0.7   \n",
            "2         1453.8                 23.1           4.7           6.1   \n",
            "3          415.4                 40.9           8.6          26.9   \n",
            "4          136.2                 26.7           2.1           4.9   \n",
            "\n",
            "   ProteinContent  RecipeServings  RecipeYield  \n",
            "0            84.7             4.0               \n",
            "1             2.4             1.0               \n",
            "2            23.8             4.0               \n",
            "3            32.7             2.0               \n",
            "4             7.4            10.0               \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zd/cww5hp2j0cj1n_8kn3hnh9c00000gn/T/ipykernel_1068/3250921411.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  description_training_data[column] = column_imp.flatten()\n"
          ]
        }
      ],
      "source": [
        "#Impute\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "#Imputers for different data types\n",
        "imp_string = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='')\n",
        "imp_num = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
        "\n",
        "# Impute over all columns\n",
        "for column in description_training_data.columns:\n",
        "    if isinstance(description_training_data[column][0], str) or column == \"RecipeYield\":\n",
        "        column_imp = imp_string.fit_transform(description_training_data[column].to_frame())\n",
        "    else:\n",
        "        column_imp = imp_num.fit_transform(description_training_data[column].to_frame())\n",
        "\n",
        "    description_training_data[column] = column_imp.flatten()\n",
        "\n",
        "print(description_training_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(30552, 22)\n",
            "(30552, 1)\n"
          ]
        }
      ],
      "source": [
        "#Save Processed Data\n",
        "description_training_data.to_csv('description_training_data.csv', index=False)\n",
        "description_training_labels.to_csv('description_training_labels.csv', index=False)\n",
        "\n",
        "print(description_training_data.shape)\n",
        "print(description_training_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Z8Jq38pJKxzi"
      },
      "outputs": [],
      "source": [
        "#Embeddings Using BERT Model\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "bert_model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "#Helper Functions\n",
        "def get_bert_embedding(text):\n",
        "    \"\"\"\n",
        "    Get BERT embeddings for a given text.\n",
        "    \"\"\"\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "    # Pass tokens through BERT model\n",
        "    with torch.no_grad():  # No gradient calculation needed for inference\n",
        "        outputs = bert_model(**inputs)\n",
        "\n",
        "    # Extract embeddings from the last hidden state (shape: [batch_size, seq_len, hidden_dim])\n",
        "    hidden_states = outputs.last_hidden_state\n",
        "\n",
        "    # Optional: Average the embeddings across the sequence for a single vector representation\n",
        "    sentence_embedding = hidden_states.mean(dim=1)\n",
        "\n",
        "    return sentence_embedding\n",
        "\n",
        "def convert_to_bert(df, column):\n",
        "  bert_embeddings = []\n",
        "  for i in range(df.shape[0]):\n",
        "    if i % 1000 == 0:\n",
        "      print(f'{column} Rows Converted: {i}')\n",
        "    bert_embeddings.append(get_bert_embedding(df[column][i]))\n",
        "\n",
        "  return bert_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3cDq9L_6Kxzi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RecipeId: 88 - <class 'numpy.int64'>\n",
            "Name: Breakfast Burritos - <class 'str'>\n",
            "Name Rows Converted: 0\n",
            "Name Rows Converted: 1000\n",
            "Name Rows Converted: 2000\n",
            "Name Rows Converted: 3000\n",
            "Name Rows Converted: 4000\n",
            "Name Rows Converted: 5000\n",
            "Name Rows Converted: 6000\n",
            "Name Rows Converted: 7000\n",
            "Name Rows Converted: 8000\n",
            "Name Rows Converted: 9000\n",
            "Name Rows Converted: 10000\n",
            "Name Rows Converted: 11000\n",
            "Name Rows Converted: 12000\n",
            "Name Rows Converted: 13000\n",
            "Name Rows Converted: 14000\n",
            "Name Rows Converted: 15000\n",
            "Name Rows Converted: 16000\n",
            "Name Rows Converted: 17000\n",
            "Name Rows Converted: 18000\n",
            "Name Rows Converted: 19000\n",
            "Name Rows Converted: 20000\n",
            "Name Rows Converted: 21000\n",
            "Name Rows Converted: 22000\n",
            "Name Rows Converted: 23000\n",
            "Name Rows Converted: 24000\n",
            "Name Rows Converted: 25000\n",
            "Name Rows Converted: 26000\n",
            "Name Rows Converted: 27000\n",
            "Name Rows Converted: 28000\n",
            "Name Rows Converted: 29000\n",
            "Name Rows Converted: 30000\n",
            "AuthorId: 1575 - <class 'numpy.int64'>\n",
            "AuthorName: lindaWWJD - <class 'str'>\n",
            "AuthorName Rows Converted: 0\n",
            "AuthorName Rows Converted: 1000\n",
            "AuthorName Rows Converted: 2000\n",
            "AuthorName Rows Converted: 3000\n",
            "AuthorName Rows Converted: 4000\n",
            "AuthorName Rows Converted: 5000\n",
            "AuthorName Rows Converted: 6000\n",
            "AuthorName Rows Converted: 7000\n",
            "AuthorName Rows Converted: 8000\n",
            "AuthorName Rows Converted: 9000\n",
            "AuthorName Rows Converted: 10000\n",
            "AuthorName Rows Converted: 11000\n",
            "AuthorName Rows Converted: 12000\n",
            "AuthorName Rows Converted: 13000\n",
            "AuthorName Rows Converted: 14000\n",
            "AuthorName Rows Converted: 15000\n",
            "AuthorName Rows Converted: 16000\n",
            "AuthorName Rows Converted: 17000\n",
            "AuthorName Rows Converted: 18000\n",
            "AuthorName Rows Converted: 19000\n",
            "AuthorName Rows Converted: 20000\n",
            "AuthorName Rows Converted: 21000\n",
            "AuthorName Rows Converted: 22000\n",
            "AuthorName Rows Converted: 23000\n",
            "AuthorName Rows Converted: 24000\n",
            "AuthorName Rows Converted: 25000\n",
            "AuthorName Rows Converted: 26000\n",
            "AuthorName Rows Converted: 27000\n",
            "AuthorName Rows Converted: 28000\n",
            "AuthorName Rows Converted: 29000\n",
            "AuthorName Rows Converted: 30000\n",
            "CookTime: nan - <class 'float'>\n",
            "PrepTime: PT35M - <class 'str'>\n",
            "PrepTime Rows Converted: 0\n",
            "PrepTime Rows Converted: 1000\n",
            "PrepTime Rows Converted: 2000\n",
            "PrepTime Rows Converted: 3000\n",
            "PrepTime Rows Converted: 4000\n",
            "PrepTime Rows Converted: 5000\n",
            "PrepTime Rows Converted: 6000\n",
            "PrepTime Rows Converted: 7000\n",
            "PrepTime Rows Converted: 8000\n",
            "PrepTime Rows Converted: 9000\n",
            "PrepTime Rows Converted: 10000\n",
            "PrepTime Rows Converted: 11000\n",
            "PrepTime Rows Converted: 12000\n",
            "PrepTime Rows Converted: 13000\n",
            "PrepTime Rows Converted: 14000\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(description_training_data[column_name][\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n\u001b[1;32m     15\u001b[0m     cur_col \u001b[39m=\u001b[39m description_training_data[column_name]\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m---> 16\u001b[0m     bert_converted[column_name] \u001b[39m=\u001b[39m convert_to_bert(cur_col, column_name)\n\u001b[1;32m     18\u001b[0m   it \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[39m# Update the DataFrame after processing all columns\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[5], line 31\u001b[0m, in \u001b[0;36mconvert_to_bert\u001b[0;34m(df, column)\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     30\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mcolumn\u001b[39m}\u001b[39;00m\u001b[39m Rows Converted: \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m   bert_embeddings\u001b[39m.\u001b[39mappend(get_bert_embedding(df[column][i]))\n\u001b[1;32m     33\u001b[0m \u001b[39mreturn\u001b[39;00m bert_embeddings\n",
            "Cell \u001b[0;32mIn[5], line 16\u001b[0m, in \u001b[0;36mget_bert_embedding\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m# Pass tokens through BERT model\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():  \u001b[39m# No gradient calculation needed for inference\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     outputs \u001b[39m=\u001b[39m bert_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m     18\u001b[0m \u001b[39m# Extract embeddings from the last hidden state (shape: [batch_size, seq_len, hidden_dim])\u001b[39;00m\n\u001b[1;32m     19\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mlast_hidden_state\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1143\u001b[0m     embedding_output,\n\u001b[1;32m   1144\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1145\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1146\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1147\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1148\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1149\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1150\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1151\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1152\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1153\u001b[0m )\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    696\u001b[0m         hidden_states,\n\u001b[1;32m    697\u001b[0m         attention_mask,\n\u001b[1;32m    698\u001b[0m         layer_head_mask,\n\u001b[1;32m    699\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    700\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    701\u001b[0m         past_key_value,\n\u001b[1;32m    702\u001b[0m         output_attentions,\n\u001b[1;32m    703\u001b[0m     )\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:627\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    624\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    625\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 627\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    628\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    629\u001b[0m )\n\u001b[1;32m    630\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    632\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pytorch_utils.py:248\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 248\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:640\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[1;32m    639\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 640\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(intermediate_output, attention_output)\n\u001b[1;32m    641\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:552\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, input_tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 552\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m    553\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    554\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#convert all string instances into bert embeddings\n",
        "bert_converted = {}\n",
        "\n",
        "#Test########\n",
        "# cur_col = description_training_data[\"Name\"].to_frame()\n",
        "# bert_converted[\"Name\"] = convert_to_bert(cur_col, \"Name\")\n",
        "# print(pd.DataFrame([bert_converted])[\"Name\"].head())\n",
        "# #############\n",
        "\n",
        "for column_name in description_training_data.columns:\n",
        "  print(f'{column_name}: {description_training_data[column_name][0]} - {type(description_training_data[column_name][0])}')\n",
        "  if isinstance(description_training_data[column_name][0], str):\n",
        "    cur_col = description_training_data[column_name].to_frame()\n",
        "    bert_converted[column_name] = convert_to_bert(cur_col, column_name)\n",
        "\n",
        "# Update the DataFrame after processing all columns\n",
        "for column_name, bert_data in bert_converted.items():\n",
        "    description_training_data[column_name] = bert_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piDlwEWjKxzi"
      },
      "outputs": [],
      "source": [
        "#Save Processed Data\n",
        "description_training_data.to_csv('description_training_data.csv', index=False)\n",
        "\n",
        "description_training_labels.to_csv('description_training_labels.csv', index=False)\n",
        "\n",
        "print(description_training_data.head())\n",
        "print(description_training_data.shape)\n",
        "print(description_training_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cwXXc95FQ0K"
      },
      "outputs": [],
      "source": [
        "#Load in Training Data and Labels\n",
        "file_path_description_train = 'description_training_data.csv'\n",
        "file_path_description_label = 'description_training_labels.csv'\n",
        "\n",
        "X = pd.read_csv(file_path_description_train)\n",
        "Y = pd.read_csv(file_path_description_label)\n",
        "\n",
        "print(X.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sl5A301gKxzj"
      },
      "outputs": [],
      "source": [
        "#train/test split\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SK7mMobKKxzj"
      },
      "outputs": [],
      "source": [
        "#Using Logistic Regressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = model.predict(X_validation)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Classification Report:\\n\", classification_report(Y_validation, Y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(Y_validation, Y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pddvkn1dKxzj"
      },
      "source": [
        "# Now we will use BERT for clustering\n",
        "We will use k-means clustering with a k value of 20 and the BERT embedding to find recipes with close similarity scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NP34jWCKxzj"
      },
      "outputs": [],
      "source": [
        "#Preparing Data\n",
        "\n",
        "#Load in Training Data and Labels\n",
        "recipes = 'recipes.csv'\n",
        "X = pd.read_csv(recipes)\n",
        "\n",
        "#Convert\n",
        "cur_col = X[\"Description\"].to_frame()\n",
        "X[\"Description\"] = convert_to_bert(cur_col, \"Description\")\n",
        "\n",
        "converted_col = X[\"Description\"].to_frame()\n",
        "\n",
        "converted_col.to_csv('bert_descriptions.csv', index=False)\n",
        "\n",
        "print(converted_col.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kItndpUCKxzj"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=20, random_state=0)\n",
        "\n",
        "kmeans.fit(converted_col)\n",
        "\n",
        "labels = kmeans.labels_\n",
        "\n",
        "centers = kmeans.cluster_centers_\n",
        "\n",
        "print(\"Labels:\", labels)\n",
        "print(\"Centers:\", centers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT2-sk15Kxzj"
      },
      "outputs": [],
      "source": [
        "#Saving Kmeans Data\n",
        "labels_df = pd.DataFrame(labels)\n",
        "centers_df = pd.DataFrame(centers)\n",
        "\n",
        "labels_df.to_csv('kmeans_labels.csv', index=False)\n",
        "centers_df.to_csv('kmeans_centers.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
